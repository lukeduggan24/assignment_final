## Which part of the design do you feel most confident about and which parts are you leastsure about

Some parts I'm confident with was the decision to use cloud functions and cloud run for the compute layer rather than always on VMs, it aligns perfectly with the use case's characteristics and the cost savings are substantial which are zero during idle periods means we aren't paying for compute resources overnight or on weekends. Then there is the layered storage strategy where the three tier approach of cloud storage, cloud sql, and BigQuery makes the most sense, it addresses different data access patterns effectively. The cloud storage show JSON device readings and CSV exports are perfect for object storage. Cloud sql for operational data the patients demographic, intervention notes, and alert configurations need ACID compliance and relational integrity. BigQuery for analytics have historical time-series data and aggregation benefit from columnar storage and with BigQuery having the ability to scan billions of rows quickly. The separation of concerns is established well for patterns and I'm confident it will perform great and be maintainable. The parts that I am least sure about is my design uses horuly batch processing for alerts and aggregations which would introduce latency, so if a patient's blood pressure spiked dangerously around 9:05 am an alert wouldn't generate until the next hourly window which would be in this case 10:00 am, this delay can be problematic. Another is the designed ingestion function to poll device manufacturer APIs is every 15 minutes, but it might not be the most optimal. The poll was chose for consistency and simplicity but it might not scale well or reflect best practices in medical device integration.

## At least one alternative architecture you considered and why you did not choose it

I considered a monolithic VM with on-premises database, it can deploy everything on a single compute engine VM this includes the flask app, postgresql database, scheduled cron jobs, and data processing scripts which will all run on one Ubuntu instance and store files in a local disk storage and not a cloud storage. I considered it because of the cost predictability with single VM cost about $5 to $15 a month regardless of usage and a lower learning curve as well where it is similar to local development environment. The reason I didn't choose it the end was there was scalability limits, there was only vertical scaling there would be an eventual performance ceiling. It additionally also doesn't align with learning objectives, the modern cloud development puts an emphasis on serverless, microservices, and managed services then cost efficiency at low usage, to pay for 24/7 uptime even when the system is idle. The approach overall would work but for a production healthcare system at scale it be looked at as an anti pattern.

## If you had 4-8 more weeks and unlimited credits, what next steps you would implement

The first thing I would do is implement cloud tracing for distributed tracing across all services and set up a custom cloud monitoring dashboard with SLIs. Then configure the error reporting with slack integration to have immediate notifications of exceptions and also implement a log based metric to track the business KPIs. I would then implement HL7 FHIR API integration to be able to pull patient medication lists, recent hospitalizations from EHR, and a problem lists which then would lead to Push RPM alert summaries back to EHR as clinical observations and handle idntity matching and data reconciliation challenges. Next I would redesign a data model to support multiple clinics/health systems as tenants and implement tenant isolation. Leading to update IAM model where clinic admins can only manage their own organization's data and implementing cross-tenant analytics for benchmarking. Finally I would analyze actual usage patterns with the cloud billing export to BigQuery and identify expensive queries and refactor. I would also implement a committed use discounts for any predictable cloud sql and compute engine workloads and negotiating enterprise pricing with a device manufacturer APIs based on volume.