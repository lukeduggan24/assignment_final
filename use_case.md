## Problem Statement
The Use Case: Remote Patient Monitoring System for Chronic Heart Failure Management

Over 6 million adults in the United States are affected by chronic heart failure (CHF) and it requires to have continuous monitoring so that it can prevent hospital readmissions. In studies it shows that 25% of CHF patients are readmitted within about 30 days of discharge, and a lot of this is often due to missing early signs of elevated blood pressure, rapid weight gain, or declining oxygen saturation. The problem is clinicians lack real-time visibility into patient vitals between office visits, this would than lead to delayed interventions. Most patients struggle to track daily measurements and don't even recognize when their own condition is deteriorating. The care teams will spend hours reviewing scattered data manually from patients logs, phone calls, and disparate monitoring devices. The goal is to have a remote patient monitoring mini-pipeline that will collect vital signs from home monitoring devices, analyzes trends, stores data centrally, and generates actionable alerts and summaries for the clinical staff. The users will be patients with CHF who are typically 65 years or older who may have recently been discharged or would have a high risk for readmission. The care coordinators that will monitor 50-100 patients remotely and can contact patient if intervention is needed. Cardiologists can also be a user, they can make treatment adjustments based on data trends and use historical data during appointments. Finally the clinical staff they would be able to enroll new patients into the monitoring programand could generate reports for billing and quality metrics. 

## Date Sources

The primary data that would be stored is device readings so things like a bluetooth-enabled home monitoring device involving a JSON format streams via device manufacturers from APIs. Some data elements required is a patient identifier, the device type, timestamp, device metadata, and vital sign measurements like weight, heart rate, blood pressure, and oxygen saturation. Next to be stored is patient demographics and care plans the use of Electronic Health Record (EHR) system export and we use a format of CSV files and would be frequently updated weekly or whenever patient enrollment would change. The data elements used would be things like patient ID, name, contact information, and date of birth. There would be diagnosis codes, medication list, assigned care coordinator, and enrollment date and program stats. The third to be stored is clinical notes and interventions the manual entry by care coordinators through web interface and the format used will be a structured form data stored in JSON, which will be needed for when staff contact patients. The data elements for this is a contact timestamp, patient-reported symptoms, contact method, follow-up required, and actions taken. Finally there is alert configurations, so with clinical decision support rules defined from the medical team it is formatted with configuration JSON file. The data for this is are alert types, trending rules, escalation protocols, and threshold rules.

## Basic Workflow

- Step 1: Data collection and ingestion, this is where the patient takes a daily measurement at home using connected devices the device will automatically transmit readings from the bluetooth to their patients smartphone. The manufacturer's would have the mobile app sends data to the cloud API and the system will poll the API every 15 minutes for any new readings. The raw JSON data is then validated for completeness, format and data is written tothe cloud storage.
- Step 2: Data storage and organization, the incoming device readings will be stored in a structured folder hierarchy and the patient demographics CSV would be loaded into the database. The historical data would be retained for 2 years and daily snapshots are created for quick access.
- Step 3: Data processing and aggregation, so every hour, a processing job scans for new raw data files. The system for each patient would calculate daily aggregates, calculates 7-day and 30-day trends, extract all readings from the past 24 hours, and it would compare current readings to patient-specific threshold from a care plan. Then processed summaries are written into a folder as CSV files.
- Step 4: Alert Generation, the alert engine will evaluate each patient summary against the clinical rules and alerts are written with columns. The critical alerts trigger immmediate notifications and there will be warning alerts that appear in the daily dashboard but won't send immediate notifications.
- Step 5: Dashboard and reporting, the care coordinators will log into web dashboard each morning and dashboard will load what today's alert CSV file which shows the active alerts sorted by severity and a patient summary CSV which shows patients latest readings. The dashboard will display a patient list, alert queue, and individual patient view. When a care coordinator clicks on a patient they can see mark alerts, document interventions, and reading history. There will also be a weekly report generation which calculates program metrics, aggregates data across all patients for that week, and an export summary report CSV.
- Step 6: Clinical intervention and feedback loop, a care coordinator will contact a patient based on alerts and if needed patients alert thresholds are adjusted in the care plan. These updated threshold would be reflected in the next processing cycle and cardiologist's review the weekly trends during patient appointments. Any of the treatment changes would be documented and the system continues monitoring to assess effectiveness of the interventions.